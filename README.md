# DL-finance-project


The paper we are studying is : "Deep Learning for Spatio-Temporal Modeling: Dynamic Traffic Flows and High Frequency Trading". The latter exposes how deep learning architectures can be used to spatio-temporal predictive modelling. Two applications are discussed. The first one is the traffic flow on a northbound section of Interstate I-55 (13 miles). The second one is short-term Futures Prices from high frequency data. We chose to focus on the second application.
This paper tries to train a deep learning architecture to predict the variations of the mid price of futures on a stock each nanosecond according to the quoted price and depth of limit order book levels ("book pressure"). The main goal here is to detect selling agressors i.e. a market crossing limit order. 
We have, so far, reproduced the structure of the neural network used in the paper and the sampling procedure. However, it seems like both can be improved drastically. A more complex deep learning architecture should be a better fit in our case. We, thus, extended their work by coding an alternative structure of neural network: the Long Short-Term Memory. Such a choice is motivated by the success LSTM networks have in the litterature when used in Spatio-Temporal prediction problems. LSTM networks have the capacity to retain certain informations through time and get rid of another part. In this sense, it successfully retains long term structure  as the periodicity of a phenomen (the aggressor sell apparition) and short term variations: the mid price variation functions of the actual state of the order book.
We have also been working on the sampling procedure to use. Indeed, when categorizing the data, we realize that there is a clear imbalance as the number of observations in which we witness a change in the mid price is roughly 0.01% of the total number of observations. This biases the training. The paper suggests oversampling and undersampling. However, a simple oversampling of the minority observations entails an overfit of these observations, whereas an undersampling of the majority data makes it compromised. We have thus been looking for methods to avoid this issue and came up with SMOTE (Synthetic Minority Over-sampling Technique), which we implemented. The discussion is still on regarding the use we can make of Generative Adversarial Networks (GANs).
